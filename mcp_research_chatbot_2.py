
#%%

# -*- coding: utf-8 -*-
import asyncio
import json
from getpass import getpass

from typing import List, Dict, TypedDict
from contextlib import AsyncExitStack

# â­ï¸ ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë³€ê²½
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

# fastmcp ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ê´€ë ¨ ëª¨ë“ˆë“¤ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
from mcp import ClientSession, StdioServerParameters, types
from mcp.client.stdio import stdio_client

import google.generativeai as genai

#%%
import os

GEMINI_API_KEY = "AIzaSyBkGZrOfFB4I2V0cH1XMKP5Iaax9knvhXA"

#%%
class ToolDefinition(TypedDict):
    name: str
    description: str
    input_schema: dict

#%%

class MCP_ChatBot:
    """
    MCP ì„œë²„ì™€ ì—°ë™í•˜ì—¬ Google Gemini ëª¨ë¸ì„ í†µí•´ ë™ì‘í•˜ëŠ” ë¹„ë™ê¸° ì±—ë´‡ í´ë¼ì´ì–¸íŠ¸ì…ë‹ˆë‹¤.
    """

    def __init__(self):
        # â­ï¸ Google API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ì…ë ¥ë°›ì•„ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        google_api_key = GEMINI_API_KEY
        if not google_api_key:
            raise ValueError("API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # â­ï¸ Gemini ëª¨ë¸ì„ ì„¤ì •í•©ë‹ˆë‹¤. (í–¥í›„ gemini-2.5-flashë¡œ ë³€ê²½ ê°€ëŠ¥)
        self.model = ChatGoogleGenerativeAI(
            model="gemini-2.5-pro",
            google_api_key=google_api_key
        )
        
        # Initialize session and client objects
        self.sessions: List[ClientSession] = [] # ì¶”ê°€
        self.exit_stack = AsyncExitStack() # ì¶”ê°€

        self.available_tools: List[ToolDefinition] = [] # ì¶”ê°€
        self.tool_to_session: Dict[str, ClientSession] = {} # ì¶”ê°€
        
        print("ğŸ¤– Google Gemini í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    
    async def connect_to_server(self, server_name: str, server_config: dict) -> None:
        """íŠ¹ì • MCP serverì— ì—°ê²°."""
        try:
            server_params = StdioServerParameters(**server_config)
            stdio_transport = await self.exit_stack.enter_async_context(
                stdio_client(server_params)
            ) # new
            read, write = stdio_transport
            session = await self.exit_stack.enter_async_context(
                ClientSession(read, write)
            ) # new
            await session.initialize()
            self.sessions.append(session)
    
            # List available tools for this session
            response = await session.list_tools()
            tools = response.tools
            print(f"\nConnected to {server_name} with tools:", [t.name for t in tools])
    
            for tool in tools: # ì¶”ê°€
                self.tool_to_session[tool.name] = session
                self.available_tools.append({
                    "name": tool.name,
                    "description": tool.description,
                    "input_schema": tool.inputSchema
                })
        except Exception as e:
            print(f"Failed to connect to {server_name}: {e}")
            
    async def connect_to_servers(self): # new
        """êµ¬ì„± íŒŒì¼ ë‚´ì˜ ëª¨ë“  MCP ì„œë²„ì— ì—°ê²°í•©ë‹ˆë‹¤."""
        try:
            with open("server_config.json", "r") as file:
                data = json.load(file)

            servers = data.get("mcpServers", {})

            for server_name, server_config in servers.items():
                await self.connect_to_server(server_name, server_config)
        except Exception as e:
            print(f"Error loading server configuration: {e}")
            raise

    async def process_query(self, query: str):
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë°›ì•„ LLMê³¼ MCP ì„œë²„ë¥¼ í†µí•´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        print("ğŸ¤” ì²˜ë¦¬ ì¤‘...")
        # â­ï¸ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
        messages = [HumanMessage(content=query)]
        
        # â­ï¸ LangChainì„ í†µí•œ í˜¸ì¶œ
        response = self.model.invoke(
            input=messages,
            tools=self.available_tools
        )

        process_query = True
        while process_query:
            # LangChain AIMessage ì‘ë‹µ ì²˜ë¦¬
            if response.content:
                # í…ìŠ¤íŠ¸ ì‘ë‹µì´ ìˆëŠ” ê²½ìš°
                print(response.content)
                if not response.tool_calls:
                    process_query = False
            
            if response.tool_calls:
                # ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš°
                messages.append(response)  # AI ë©”ì‹œì§€ ì¶”ê°€
                
                for tool_call in response.tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    
                    print(f"Calling tool {tool_name} with args {tool_args}")
                    
                    # ë„êµ¬ ì‹¤í–‰
                    session = self.tool_to_session[tool_name]
                    result = await session.call_tool(tool_name, arguments=tool_args)
                    
                    # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ToolMessageë¡œ ì¶”ê°€
                    tool_message = ToolMessage(
                        content=str(result.content),
                        tool_call_id=tool_call["id"]
                    )
                    messages.append(tool_message)
                
                # ë‹¤ìŒ ì‘ë‹µ ìƒì„±
                response = self.model.invoke(
                    input=messages,
                    tools=self.available_tools
                )
                
                # ìµœì¢… ì‘ë‹µ í™•ì¸
                if response.content and not response.tool_calls:
                    print(response.content)
                    process_query = False
            else:
                process_query = False

    async def chat_loop(self):
        """ëŒ€í™”í˜• ì±„íŒ… ë£¨í”„ë¥¼ ì‹¤í–‰"""
        print("\nMCP Chatbot Started!")
        print("ìš”ì²­ ì…ë ¥í•˜ê±°ë‚˜ ì¢…ë£Œë¥¼ ìœ„í•´ì„œëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”.")

        while True:
            try:
                query = input("\nQuery: ").strip()

                if query.lower() == 'quit':
                    break

                await self.process_query(query)
                print("\n")

            except Exception as e:
                print(f"\nError: {str(e)}")

    async def cleanup(self): # new
        """AsyncExitStackì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¦¬ì†ŒìŠ¤ë¥¼ ê¹”ë”í•˜ê²Œ ë‹«ìŠµë‹ˆë‹¤."""
        await self.exit_stack.aclose()

#%%

async def main():
    """ì±—ë´‡ì˜ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    chatbot = MCP_ChatBot()
    try:
        # mcp í´ë¼ì´ì–¸íŠ¸ì™€ ì„¸ì…˜ì€ "with"ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # ì´ì „ ë ˆìŠ¨ê³¼ ê°™ì´
        # ë”°ë¼ì„œ ì •ë¦¬ëŠ” ìˆ˜ë™ìœ¼ë¡œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
        await chatbot.connect_to_servers() # new!
        await chatbot.chat_loop()
    finally:
        await chatbot.cleanup() #new!


if __name__ == "__main__":
    try:
        # í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬: pip install langchain-google-genai fastmcp
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\ní”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")


    
#%%