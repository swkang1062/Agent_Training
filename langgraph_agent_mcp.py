# -*- coding: utf-8 -*-
"""
Created on Sun Aug 31 21:35:53 2025

@author: SW Kang
"""

# langgraph_agent_mcp.py

# -*- coding: utf-8 -*-
import os
import json
import subprocess
import atexit
from getpass import getpass
from typing import Annotated, TypedDict
import operator

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain.tools import tool
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode

# --- 1. MCP ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ---
print("ğŸ“¡ MCP ì„œë²„ë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤...")
mcp_server_process = subprocess.Popen(
    ['python', 'mcp_server.py'],
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
    text=True,
    encoding='utf-8'
)

# í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ìì‹ í”„ë¡œì„¸ìŠ¤ë„ í•¨ê»˜ ì¢…ë£Œë˜ë„ë¡ ë“±ë¡
@atexit.register
def cleanup():
    print("ğŸ§¹ ì—ì´ì „íŠ¸ê°€ ì¢…ë£Œë˜ì–´ MCP ì„œë²„ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.")
    if mcp_server_process.poll() is None:
        mcp_server_process.terminate()
        mcp_server_process.wait()
    print("ğŸ‘‹ MCP ì„œë²„ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# MCP ì„œë²„ì™€ í†µì‹ í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
def call_mcp_tool(method: str, **params) -> str:
    """MCP ì„œë²„ì˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    request_id = 1 # ê°„ë‹¨í•œ ì˜ˆì œì´ë¯€ë¡œ IDëŠ” ê³ ì •
    request = {
        "jsonrpc": "2.0",
        "method": method,
        "params": params,
        "id": request_id,
    }
    # ìš”ì²­ì„ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì„œë²„ì˜ stdinìœ¼ë¡œ ì „ì†¡
    mcp_server_process.stdin.write(json.dumps(request) + '\n')
    mcp_server_process.stdin.flush()

    # ì„œë²„ì˜ stdoutì—ì„œ ì‘ë‹µì„ ì½ìŒ
    response_line = mcp_server_process.stdout.readline()
    if not response_line:
        return json.dumps({"error": "MCP ì„œë²„ë¡œë¶€í„° ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."})

    response = json.loads(response_line)
    
    # ì—ëŸ¬ê°€ ìˆëŠ”ì§€ í™•ì¸
    if 'error' in response:
        return json.dumps(response['error'])

    return response.get('result', '')

# --- 2. API í‚¤ ì„¤ì • (ì—ì´ì „íŠ¸ìš©) ---
# ì—ì´ì „íŠ¸ì˜ LLMì´ ì‚¬ìš©í•  API í‚¤
    
os.environ["GEMINI_API_KEY"] = "AIzaSyBkGZrOfFB4I2V0cH1XMKP5Iaax9knvhXA"
os.environ["TAVILY_API_KEY"] = "Your Tavily Key"
    
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY") 
print("GEMINI_API_KEY == ", GEMINI_API_KEY)

# --- 3. MCP ì„œë²„ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” LangChain ë„êµ¬ ì •ì˜ ---
# ê¸°ì¡´ í•¨ìˆ˜ë“¤ì˜ docstringì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ LLMì´ í•¨ìˆ˜ì˜ ì—­í• ì„ ì´í•´í•˜ë„ë¡ í•©ë‹ˆë‹¤.
@tool
def get_specific_date(date_description: str) -> str:
    """ìì—°ì–´ë¡œ ëœ ë‚ ì§œ í‘œí˜„ì„ ì‹¤ì œ ë‚ ì§œë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    return call_mcp_tool('get_specific_date', date_description=date_description)

@tool
def verify_location(location_name: str) -> str:
    """ì§€ì—­ëª…ì„ ê²€ì¦í•˜ê³  ì •í™•í•œ ìœ„ì¹˜ ì •ë³´ë¥¼ Gemini Flash ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    return call_mcp_tool('verify_location', location_name=location_name)

@tool
def search_weather(location: str, date: str) -> str:
    """íŠ¹ì • ì§€ì—­ì˜ íŠ¹ì • ë‚ ì§œ ë‚ ì”¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜"""
    return call_mcp_tool('search_weather', location=location, date=date)

# --- 4. LangGraph Agent ìƒì„± (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©) ---

# ì—ì´ì „íŠ¸ ìƒíƒœ(State) ì •ì˜
class AgentState(TypedDict):
    messages: Annotated[list, operator.add]

# ë„êµ¬ ë° ëª¨ë¸ ì„¤ì •
tools = [get_specific_date, verify_location, search_weather]
tool_node = ToolNode(tools)

# ì‚¬ìš©í•  ëª¨ë¸ ì •ì˜ ë° ë„êµ¬ ë°”ì¸ë”©
model = ChatGoogleGenerativeAI(model="gemini-2.5-pro", temperature=0, api_key=GEMINI_API_KEY)
model = model.bind_tools(tools)

# ë…¸ë“œ(Node) ë° ì—£ì§€(Edge) ì •ì˜
def call_model(state: AgentState):
    """LLMì„ í˜¸ì¶œí•˜ëŠ” ì—ì´ì „íŠ¸ ë…¸ë“œ"""
    messages = state['messages']
    response = model.invoke(messages)
    return {"messages": [response]}

def should_continue(state: AgentState):
    """Toolì„ í˜¸ì¶œí• ì§€, ì•„ë‹ˆë©´ ì‚¬ìš©ìì—ê²Œ ìµœì¢… ë‹µë³€ì„ í• ì§€ ê²°ì •í•©ë‹ˆë‹¤."""
    # Actionì€ ë‹µì„ ì–»ì„ ë•Œê¹Œì§€ ìµœëŒ€ 10ë²ˆ ë°˜ë³µ
    # Human + 10*(AI+Tool)) -> ë©”ì‹œì§€ ìˆ˜ 21
    if len(state['messages']) > 21:
        print("ğŸš¦ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜(10íšŒ)ì— ë„ë‹¬í•˜ì—¬ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return "end"
    if state['messages'][-1].tool_calls:
        return "continue"
    return "end"

# ê·¸ë˜í”„(Graph) ìƒì„±
workflow = StateGraph(AgentState)
workflow.add_node("agent", call_model)
workflow.add_node("action", tool_node)
workflow.set_entry_point("agent")
workflow.add_conditional_edges(
    "agent", should_continue, {"continue": "action", "end": END}
)
workflow.add_edge("action", "agent")
    
app = workflow.compile()

# --- 5. ì‹¤í–‰ ì½”ë“œ (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©) ---
def run_agent(query: str):
    """LangGraph ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
    system_message = (
        "ë‹¹ì‹ ì€ ë‚ ì”¨ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” ì „ë¬¸ ì—ì´ì „íŠ¸ 'ë‚ ì”¨ë´‡'ì…ë‹ˆë‹¤. "
        "ì£¼ì–´ì§„ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. "
        "ëª¨ë“  ë‹¨ê³„ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê³ , ìµœì¢… ë‹µë³€ì€ ë°˜ë“œì‹œ **ì œì£¼ë„ ì‚¬íˆ¬ë¦¬**ë¡œ, "
        "ì •ê° ìˆê³  ì¹œì ˆí•˜ê²Œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”. (ì˜ˆ: ~í–ˆìˆ˜ë‹¤, ~ê½ˆ?, ~ê±¸ë§ˆì”¸)"
    )
    initial_messages = [
        HumanMessage(content=system_message),
        HumanMessage(content=query)
    ]
    final_state = app.invoke({"messages": initial_messages})
    final_answer = final_state['messages'][-1]
    print("\n" + "="*50)
    print("âœ… ìµœì¢… ë‹µë³€")
    print("="*50)
    print(final_answer.content)

if __name__ == "__main__":
    # MCP ì„œë²„ê°€ ë¶€íŒ…ë  ì‹œê°„ì„ ì ì‹œ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    import time
    time.sleep(2)
    
    os.environ["GEMINI_API_KEY"] = "Your GEMINI API Key"
    os.environ["TAVILY_API_KEY"] = "Your Tavily API Key"
    
    
    print("\nğŸ¤– ì œì£¼ë„ ì‚¬íˆ¬ë¦¬ ë‚ ì”¨ ì—ì´ì „íŠ¸ 'ë‚ ì”¨ë´‡'ì´ë¼ê½ˆ. ë¬´ì‹ ê±° ë¬¼ì–´ë³´ì¿ ê´‘? (ì¢…ë£Œ: 'quit')")
    while True:
        user_input = input("\nğŸ‘¤ ì§ˆë¬¸: ")
        if user_input.lower() in ["quit", "exit", "ì¢…ë£Œ"]:
            break
        if not user_input:
            continue
        run_agent(user_input)


# ë£¨í”„ê°€ ëë‚˜ë©´ atexitì— ë“±ë¡ëœ cleanup í•¨ìˆ˜ê°€ ìë™ìœ¼ë¡œ í˜¸ì¶œë©ë‹ˆë‹¤.
