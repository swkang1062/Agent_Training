
#%%

# -*- coding: utf-8 -*-
import asyncio
import json
from getpass import getpass
from typing import List

# â­ï¸ ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë³€ê²½
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

# fastmcp ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ê´€ë ¨ ëª¨ë“ˆë“¤ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
from mcp import ClientSession, StdioServerParameters, types
from mcp.client.stdio import stdio_client


#%%
import os

### êµìœ¡ìš© Key
GEMINI_API_KEY = "AIzaSyBkGZrOfFB4I2V0cH1XMKP5Iaax9knvhXA"
#%%

class MCP_ChatBot:
    """
    MCP ì„œë²„ì™€ ì—°ë™í•˜ì—¬ Google Gemini ëª¨ë¸ì„ í†µí•´ ë™ì‘í•˜ëŠ” ë¹„ë™ê¸° ì±—ë´‡ í´ë¼ì´ì–¸íŠ¸ì…ë‹ˆë‹¤.
    """

    def __init__(self):
        # â­ï¸ Google API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ì…ë ¥ë°›ì•„ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        google_api_key = GEMINI_API_KEY
        if not google_api_key:
            raise ValueError("API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # â­ï¸ Gemini ëª¨ë¸ì„ ì„¤ì •í•©ë‹ˆë‹¤. (í–¥í›„ gemini-2.5-flashë¡œ ë³€ê²½ ê°€ëŠ¥)
        self.model = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            google_api_key=google_api_key
        )
        self.model_with_tools = None # ë„êµ¬ê°€ ë°”ì¸ë”©ëœ ëª¨ë¸
        
        # MCP ì„œë²„ ì„¸ì…˜ ë° ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        self.session: ClientSession = None
        self.available_tools: List[dict] = []
        print("ğŸ¤– Google Gemini í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    async def process_query(self, query: str):
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë°›ì•„ LLMê³¼ MCP ì„œë²„ë¥¼ í†µí•´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        print("ğŸ¤” ì²˜ë¦¬ ì¤‘...")
        # â­ï¸ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
        messages = [HumanMessage(content=query)]

        # ìµœëŒ€ 5ë²ˆì˜ ë„êµ¬ í˜¸ì¶œì„ í—ˆìš©í•©ë‹ˆë‹¤.
        for _ in range(5):
            if not self.model_with_tools:
                raise RuntimeError("ëª¨ë¸ì— ë„êµ¬ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")

            # â­ï¸ ëª¨ë¸ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.
            ai_response: AIMessage = await self.model_with_tools.ainvoke(messages)
            messages.append(ai_response)

            # â­ï¸ ë„êµ¬ í˜¸ì¶œ(tool_calls)ì´ ì—†ìœ¼ë©´, ì‘ë‹µì„ ì¶œë ¥í•˜ê³  ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
            
            print("ai_response == ", ai_response)
            
            if not ai_response.tool_calls:
                print(f"\nğŸ’¬ ì±—ë´‡:\n{ai_response.content}")
                break
            
            # â­ï¸ ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´ MCP ì„œë²„ë¥¼ í†µí•´ ì‹¤í–‰í•©ë‹ˆë‹¤.
            tool_results = []
            for tool_call in ai_response.tool_calls:
                
                                 
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call["id"]
                
                print(f"ğŸ› ï¸  ë„êµ¬ í˜¸ì¶œ: {tool_name} (ì¸ìˆ˜: {tool_args})")
                

                result = await self.session.call_tool(tool_name, arguments=tool_args)

                print("result == ", result)
                # â­ï¸ ê²°ê³¼ë¥¼ LangChainì˜ ToolMessage í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
                tool_results.append(
                    ToolMessage(content=result.content, tool_call_id=tool_id)
                )
            
            messages.extend(tool_results)

    async def chat_loop(self):
        """ì‚¬ìš©ìì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ëŒ€í™” ë£¨í”„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("\nâœ… MCP ì±—ë´‡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì‹œê±°ë‚˜ 'quit'ë¥¼ ì…ë ¥í•˜ì—¬ ì¢…ë£Œí•˜ì„¸ìš”.")

        while True:
            try:
                query = await asyncio.to_thread(input, "\nğŸ§‘â€ğŸ’» ë‹¹ì‹ ì˜ ì§ˆë¬¸: ")
                if query.strip().lower() == 'quit':
                    print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                if not query.strip():
                    continue
                await self.process_query(query)
            except (KeyboardInterrupt, EOFError):
                print("\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nğŸš¨ ì˜¤ë¥˜ ë°œìƒ: {e}")

    async def connect_to_server_and_run(self):
        """MCP ì„œë²„ì— ì—°ê²°í•˜ê³ , ë„êµ¬ë¥¼ ì„¤ì •í•œ í›„, ì±—ë´‡ ë£¨í”„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
        
        ############# stdio ################
        server_params = StdioServerParameters(
            command="python", # 'uv run' ëŒ€ì‹  'python'ì„ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½
            args=["mcp_research_server.py"], # ì„œë²„ íŒŒì¼ ì´ë¦„ ë³€ê²½
        )
        print(f"ğŸ”Œ ì„œë²„ ì‹¤í–‰ ì‹œë„: {' '.join([server_params.command] + server_params.args)}")
        print("server_params == ", server_params)

        async with stdio_client(server_params) as (read, write):
            async with ClientSession(read, write) as session:
                self.session = session
                await session.initialize()
        
                response = await session.list_tools()
                tools = response.tools
        
                print("\nğŸ”— ì„œë²„ ì—°ê²° ì„±ê³µ! ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:", [tool.name for tool in tools])
        
                # â­ï¸ LangChainì˜ .bind_tools()ê°€ ì´í•´í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë„êµ¬ ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
                # 'input_schema'ë¥¼ 'parameters'ë¡œ í‚¤ ì´ë¦„ì„ ë³€ê²½í•©ë‹ˆë‹¤.
                self.available_tools = [{
                    "name": tool.name,
                    "description": tool.description,
                    "input_schema": tool.inputSchema
                } for tool in tools]
        
                print("self.available_tools == ", self.available_tools)
                # â­ï¸ Gemini ëª¨ë¸ì— ë„êµ¬ë¥¼ ë°”ì¸ë”©í•©ë‹ˆë‹¤.
                self.model_with_tools = self.model.bind_tools(self.available_tools)
                
                print("tools are bounded ... ")
        
                await self.chat_loop()
        ################################################        
        
        
        await self.chat_loop()
#%%

async def main():
    """ì±—ë´‡ì˜ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    try:
        chatbot = MCP_ChatBot()
        await chatbot.connect_to_server_and_run()
    except ValueError as e:
        print(f"ğŸš¨ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    except Exception as e:
        print(f"ğŸš¨ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ë¡œ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤: {e}")

if __name__ == "__main__":
    try:
        # í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬: pip install langchain-google-genai fastmcp
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\ní”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")


    
#%%